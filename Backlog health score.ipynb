{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantified backlog state = Sum(Rule \\* Weight \\* 10)\n",
    "\n",
    "This will give the team clear information about backlog state score in a number from 1-10 (1 - worst, 10 - best )\n",
    "Weights need to sum up to 100%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jira import JIRA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from numpy import nan\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#to show all rules descriptions\n",
    "pd.set_option('max_colwidth',200)\n",
    "\n",
    "rules = pd.DataFrame()\n",
    "rules['rule'] = ''\n",
    "rules['weight'] = 0\n",
    "rules['value'] = 0\n",
    "\n",
    "rules['rule'] = ['In next 2 sprints there are items in Backlog state that SP sum is greater than estimated velocity, there are no items assigned to sprint that are not in Backlog state - Y/N',\n",
    "                '#rule 1 Planned next 3 versions (all items estimated and in Backlog or started state (not in presprint) - Y/N',\n",
    "                '% of Must, Urgent, Should items that are estimated regardless of status',\n",
    "                '% of key milestone items estimated and in Backlog status']\n",
    "rules['weight'] = [0.4, 0.25, 0.25, 0.1]\n",
    "\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules sum should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rules.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Set up nextSprint, currentVersion, nextVersion values.\n",
    "\n",
    "They can be loaded automatically from Jira too.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nextSprints = ['IC - #4 20180219 - 1.13', 'IC - #5 20180305 - 1.14']\n",
    "\n",
    "#velocity used to check if sprints are planned correctly\n",
    "estimatedVelocity = 13\n",
    "\n",
    "nextVersions = ['1.12', '1.13', '1.14', '1.15', '1.16']\n",
    "milestones = ['Frimley MVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jira_url = 'https://kainos-evolve.atlassian.net'\n",
    "jira = JIRA(jira_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download next 2 sprints names\n",
    "from jira.client import GreenHopper\n",
    "options = {'server': jira_url}\n",
    "gh = GreenHopper(options)\n",
    "sprintsRaw = gh.sprints(285)\n",
    "\n",
    "sprints = pd.DataFrame()\n",
    "sprints['name'] = ''\n",
    "sprints['state'] = ''\n",
    "\n",
    "for sprint in sprintsRaw:\n",
    "    sprints = sprints.append(\n",
    "            {\n",
    "                'name': sprint.name,\n",
    "                'state': sprint.state\n",
    "            }, ignore_index=True)\n",
    "sprints = sprints.loc[(sprints['state'] == 'FUTURE')]\n",
    "sprints.sort_values(\"name\", inplace=True)\n",
    "\n",
    "nextSprints = sprints.head(2)['name'].tolist()\n",
    "nextSprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule 0\n",
    "#In next 2 sprints there are items in Backlog state that SP sum is greater than estimated velocity, \n",
    "#there are no items assigned to sprint that are not in Backlog state - Y/N\n",
    "#bugs don't have to be estimated\n",
    "\n",
    "jql = 'sprint in (\"{}\") and type != Bug and status = Backlog and type not in subTaskIssueTypes()'.format('\", \"'.join(nextSprints))\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['sprint'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "\n",
    "for issue in issuesRaw:\n",
    "    for rawSprint in issue.fields.customfield_10007:\n",
    "        #unfortunately sprint information is encoded and regex is needed\n",
    "        matches = re.search('name=(.*?),', rawSprint)\n",
    "        issues = issues.append(\n",
    "            {\n",
    "             'key': issue.key,\n",
    "             'type': issue.fields.issuetype.name,\n",
    "             'status': issue.fields.status.name,\n",
    "             'SP' : issue.fields.customfield_10005,\n",
    "             'summary': issue.fields.summary,\n",
    "             'sprint' : matches.group(1)\n",
    "            }, ignore_index=True)\n",
    "\n",
    "issues.fillna(value=nan, inplace=True)\n",
    "issues\n",
    "#issues.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "sprints = issues.groupby(['sprint']).agg({'SP':'sum'})\n",
    "sprints = sprints.loc[(sprints['SP'] >= estimatedVelocity)]\n",
    "sprints\n",
    "#non zero SP sprints number should be equal to number of next sprints\n",
    "rule_value = (len(sprints) == len(nextSprints))\n",
    "rules.at[0, 'value'] = int(rule_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule 1 Planned next 3 versions (all items estimated and in Backlog or started state (not in presprint) - Y/N\n",
    "jql = 'fixVersion in (\"{}\") and type not in subTaskIssueTypes()'.format('\", \"'.join(nextVersions))\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['version'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "\n",
    "#add issues to dataframe\n",
    "for issue in issuesRaw:\n",
    "    #issue may have many versions - in this approach, one version per issue is recommended\n",
    "    for fixVersion in issue.fields.fixVersions:\n",
    "        if(fixVersion.name in nextVersions):\n",
    "            issues = issues.append(\n",
    "                {'version': fixVersion.name, \n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP': issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                 'team' : str(issue.fields.customfield_14200),\n",
    "                }, ignore_index=True)\n",
    "            \n",
    "issues = issues.loc[~(issues['status'].isin(['Completed', 'Rejected']))]\n",
    "\n",
    "#indicate not estimated issues, bugs don't have to be estimated\n",
    "issues['isEstimated'] = False\n",
    "issues.loc[(issues['type'].isin(['Bug', 'Epic'])), ['isEstimated']] = True\n",
    "issues.loc[(issues['type'] != 'Bug') & ~(issues['SP'].isnull()), ['isEstimated']] = True\n",
    "\n",
    "#indicate items in presprint\n",
    "issues['inPresprint'] = False\n",
    "issues.loc[(issues['status'].isin(['Awaiting Prioritisation', 'PO Refinement', 'UX Refinement', 'QA Refinement', 'Tech Refinement', \n",
    "                                  'Tech Refinement', 'Estimation'])), ['inPresprint']] = True\n",
    "issues.sort_values(\"version\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "issues = issues.loc[(issues['inPresprint'] == True) | (issues['isEstimated'] == False)]\n",
    "issues\n",
    "\n",
    "rule_value = len(issues) == 0\n",
    "rules.at[1, 'value'] = int(rule_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule 2\n",
    "# % of Must, Urgent, Should items that are estimated regardless of status\n",
    "# bugs don't have to be estimated\n",
    "jql = 'project = VXT and priority in (Must,Urgent,Should) and type != Bug and type not in subTaskIssueTypes()'\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['version'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "issues['priority'] = ''\n",
    "\n",
    "#add issues to dataframe\n",
    "for issue in issuesRaw:\n",
    "    #issue may have many versions - in this approach, one version per issue is recommended\n",
    "    for fixVersion in issue.fields.fixVersions:\n",
    "        if(fixVersion.name in nextVersions):\n",
    "            issues = issues.append(\n",
    "                {'version': fixVersion.name, \n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP': issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                 'priority' : str(issue.fields.priority.name),\n",
    "                }, ignore_index=True)\n",
    "issues\n",
    "\n",
    "rule_value = round(len(issues.loc[~(issues['SP'].isnull())]) / len(issues), 2)\n",
    "rules.at[2, 'value'] = rule_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of key milestone items estimated and in Backlog status\n",
    "jql = 'project = VXT and type != Epic and status not in (Rejected, Completed) and type not in subTaskIssueTypes() and fixVersion in (\"' + '\", \"'.join(milestones) + '\")'\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['version'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "\n",
    "#add issues to dataframe\n",
    "for issue in issuesRaw:\n",
    "    #issue may have many versions - in this approach, one version per issue is recommended\n",
    "    for fixVersion in issue.fields.fixVersions:\n",
    "        if(fixVersion.name in milestones):\n",
    "            issues = issues.append(\n",
    "                {'version': fixVersion.name, \n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP': issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                }, ignore_index=True)\n",
    "            \n",
    "issues['isEstimated'] = False\n",
    "issues.loc[(issues['type'] == 'Bug'), ['isEstimated']] = True\n",
    "issues.loc[(issues['type'] != 'Bug') & ~(issues['SP'].isnull()), ['isEstimated']] = True\n",
    "issues\n",
    "\n",
    "rule_value = round(len(issues.loc[(issues['isEstimated'] == True)]) / len(issues), 2)\n",
    "rule_value\n",
    "rules.at[3, 'value'] = rule_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules['score'] = rules.weight * rules.value * 10\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(sum(rules['score']), 2)\n",
    "\n",
    "\n",
    "%store -r\n",
    "\n",
    "if not 'scores' in globals():\n",
    "    scores = pd.DataFrame()\n",
    "    scores['date'] = ''\n",
    "    scores['score'] = 0\n",
    "\n",
    "scores = scores.append(\n",
    "            {\n",
    "             'date': pd.to_datetime('now'),\n",
    "             'score': score,\n",
    "            }, ignore_index=True)\n",
    "\n",
    "%store scores\n",
    "\n",
    "print(\"Backlog score {} / 10\".format(score))\n",
    "\n",
    "_ = plt.plot(scores['date'], scores['score'], \"-r.\")\n",
    "\n",
    "_ = plt.xticks(rotation='vertical')\n",
    "_ = plt.ylabel('Backlog score')\n",
    "_ = plt.xlabel('Time')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
