{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backlog scoring calculations\n",
    "## How healthy is your backlog?\n",
    "\n",
    "In the fast paced development project environment it's very important to have meaningful and easy to understand metrics. Those metrics are foundation of data-driven decisions and can give you and the team sense of direction in everyday actions.\n",
    "\n",
    "Here, I'd like to present idea of backlog scoring - one number that could give you meaningful information about the shape of a backlog in your team.\n",
    "\n",
    "Quantified backlog state is simply sum of scoring for chosen rules that are summed and multiplied by maximium score. The result should be a number from 1-10 (1 - worst, 10 - best). \n",
    "$$Backlog\\ Score=\\sum_{i=0}^n score_i * weight_i * MaxScore$$ \n",
    "\n",
    "Using the persistence capabilities of Jupyter Notebook it will be also possible to track the trend of the scoring in time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jira import JIRA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from jira.client import GreenHopper\n",
    "from numpy import nan\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'd like to propose 4 rules:\n",
    "* % of planned 2 sprints. there are items in Backlog state that SP sum is equal to estimated velocity (+-20%), there are no items assigned to sprint that are not in Backlog state\n",
    "* Planned next 3 versions (all items estimated and in Backlog or started state (not in presprint) - [Y/N]\n",
    "* % of Must, Urgent, Should items that are estimated regardless of status'\n",
    "* % of key milestone (major version) items estimated and in Backlog status\n",
    "\n",
    "\n",
    "Below you can see how to set up rules with weights. In my example most important is to ensure that next 2 sprints are planned. The 0 rule have weight of 0.4 and other rules weights are 0.25, 0.25 and 1. You can change those rules or add more. All weights need to sum up to 1.\n",
    "\n",
    "Above rules make sense for our project. You can modify them or add new!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show full rules descriptions\n",
    "pd.set_option('max_colwidth',200)\n",
    "\n",
    "rules = pd.DataFrame()\n",
    "rules['rule'] = ''\n",
    "rules['weight'] = 0\n",
    "rules['value'] = 0\n",
    "\n",
    "rules['rule'] = ['% of planned 2 sprints. there are items in Backlog state that SP sum is equal to estimated velocity \\\n",
    "(+-20%), there are no items assigned to sprint that are not in Backlog state',\n",
    "                'Planned next 3 versions (all items estimated and in Backlog or started state (not in presprint) - Y/N',\n",
    "                '% of Must, Urgent, Should items that are estimated regardless of status',\n",
    "                '% of key milestone items estimated and in Backlog status']\n",
    "rules['weight'] = [0.4, 0.25, 0.25, 0.1]\n",
    "\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules sum should be equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rules.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Set up estimatedVelocity, nextVersion and milestones values.\n",
    "\n",
    "They can be loaded automatically from Jira but this is not a scope of this article.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#velocity used to check if sprints are planned correctly\n",
    "estimatedVelocity = 14\n",
    "\n",
    "nextVersions = ['1.12', '1.13', '1.14', '1.15', '1.16']\n",
    "milestones = ['Milestone 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jira address will be needed to load data. Credentials are stored in ~/.rcnet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jira_url = 'https://kainos-evolve.atlassian.net'\n",
    "jira = JIRA(jira_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Board id need to be specified to download sprint information. You can find it in the address of your board in Jira.\n",
    "\n",
    "<img src=\"./images/boardId.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download next 2 sprints names\n",
    "\n",
    "options = {'server': jira_url}\n",
    "gh = GreenHopper(options)\n",
    "\n",
    "#you need to specify the board id\n",
    "sprintsRaw = gh.sprints(285)\n",
    "\n",
    "sprints = pd.DataFrame()\n",
    "sprints['name'] = ''\n",
    "sprints['state'] = ''\n",
    "\n",
    "for sprint in sprintsRaw:\n",
    "    sprints = sprints.append(\n",
    "            {\n",
    "                'name': sprint.name,\n",
    "                'state': sprint.state\n",
    "            }, ignore_index=True)\n",
    "\n",
    "#we're interested only in not started sprints\n",
    "sprints = sprints.loc[(sprints['state'] == 'FUTURE')]\n",
    "sprints.sort_values(\"name\", inplace=True)\n",
    "\n",
    "nextSprints = sprints.head(2)['name'].tolist()\n",
    "nextSprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First rule focus on the next 2 sprints. To achieve max result issues in 2 of next sprints should be refined and estimated. The calculated velocity for each next sprint should be similar to estimated in +-20% range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule 0\n",
    "#In next 2 sprints there are items in Backlog state that SP sum is equal to estimated velocity (+-20%), \n",
    "#there are no items assigned to sprint that are not in Backlog state \n",
    "#bugs don't have to be estimated\n",
    "\n",
    "# find all issues in specified sprints that are not bugs and are in backlog status\n",
    "jql = 'sprint in (\"{}\") and type != Bug and status = Backlog and type not in subTaskIssueTypes()'.format('\", \"'.join(nextSprints))\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['sprint'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "\n",
    "for issue in issuesRaw:\n",
    "    for rawSprint in issue.fields.customfield_10007:\n",
    "        #unfortunately sprint information is encoded and regex is needed\n",
    "        matches = re.search('name=(.*?),', rawSprint)\n",
    "        currentSprint = matches.group(1)\n",
    "        #we're only interested in issues assigned to specific sprints\n",
    "        if(currentSprint in nextSprints):\n",
    "            issues = issues.append(\n",
    "                {\n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP' : issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                 'sprint' : currentSprint\n",
    "                }, ignore_index=True)\n",
    "\n",
    "issues.fillna(value=nan, inplace=True)\n",
    "issues\n",
    "#issues.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "sprints = issues.groupby(['sprint']).agg({'SP':'sum'})\n",
    "sprints\n",
    "sprints = sprints.loc[(sprints['SP'] >= estimatedVelocity - estimatedVelocity * .2) &\n",
    "                     (sprints['SP'] <= estimatedVelocity + estimatedVelocity * .2)]\n",
    "\n",
    "#% of sprints that meet condition should be equal to number of next sprints\n",
    "rule_value = len(sprints) / len(nextSprints)\n",
    "rules.at[0, 'value'] = int(rule_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd rule checks if 3 next versions in Jira (manually set up above) are initially estimated. Initial estimation in Story Points with team velocity can give us view on when the team will be ready to deliver specified versions. \n",
    "\n",
    "To see how to create stacked burndown for multiple versions see: [https://github.com/robert-krasinski/JiraAndPythonForManagers/blob/master/Burndown%20chart%20for%20multiple%20versions.ipynb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule 1 Planned next 3 versions (all items estimated and in Backlog or started state (not in state before backlog) - Y/N\n",
    "jql = 'fixVersion in (\"{}\") and type not in subTaskIssueTypes()'.format('\", \"'.join(nextVersions))\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['version'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "\n",
    "#add issues to dataframe\n",
    "for issue in issuesRaw:\n",
    "    #issue may have many versions - in this approach, one version per issue is recommended\n",
    "    for fixVersion in issue.fields.fixVersions:\n",
    "        #only specific versions should be taken into consideration\n",
    "        if(fixVersion.name in nextVersions):\n",
    "            issues = issues.append(\n",
    "                {'version': fixVersion.name, \n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP': issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                 'team' : str(issue.fields.customfield_14200),\n",
    "                }, ignore_index=True)\n",
    "\n",
    "#completed and rejected issues don't need to be estimated       \n",
    "issues = issues.loc[~(issues['status'].isin(['Completed', 'Rejected']))]\n",
    "\n",
    "#indicate not estimated issues, bugs don't have to be estimated\n",
    "issues['isEstimated'] = False\n",
    "issues.loc[(issues['type'].isin(['Bug', 'Epic'])), ['isEstimated']] = True\n",
    "issues.loc[(issues['type'] != 'Bug') & ~(issues['SP'].isnull()), ['isEstimated']] = True\n",
    "\n",
    "#indicate items in presprint. PreSprint states in this case are the states before Backlog. Item needs to be refined\n",
    "#before a team start working on them.\n",
    "\n",
    "issues['inPresprint'] = False\n",
    "issues.loc[(issues['status'].isin(['Awaiting Prioritisation', 'PO Refinement', 'UX Refinement', 'QA Refinement', 'Tech Refinement', \n",
    "                                  'Tech Refinement', 'Estimation'])), ['inPresprint']] = True\n",
    "issues.sort_values(\"version\", inplace=True)\n",
    "\n",
    "\n",
    "issues = issues.loc[(issues['inPresprint'] == True) | (issues['isEstimated'] == False)]\n",
    "issues\n",
    "\n",
    "#there should be no issues without SP and in earlier states than Backlog \n",
    "rule_value = len(issues) == 0\n",
    "rules.at[1, 'value'] = int(rule_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd rule ensures that high priority items are estimated (except Bug type). There is plenty of space for improvement here. For example you could measure how many high priority bugs in Backlog are stored there specific time treshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule 2\n",
    "# % of Must, Urgent, Should items that are estimated regardless of status\n",
    "# bugs don't have to be estimated\n",
    "jql = 'project = VXT and priority in (Must,Urgent,Should) and type != Bug and type not in subTaskIssueTypes() \\\n",
    "and status not in (Rejected, Completed)'\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['version'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "issues['priority'] = ''\n",
    "\n",
    "#add issues to dataframe\n",
    "for issue in issuesRaw:\n",
    "    #issue may have many versions - in this approach, one version per issue is recommended\n",
    "    for fixVersion in issue.fields.fixVersions:\n",
    "        #only specific versions are needed (issue may be assigned to many)\n",
    "        if(fixVersion.name in nextVersions):\n",
    "            issues = issues.append(\n",
    "                {'version': fixVersion.name, \n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP': issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                 'priority' : str(issue.fields.priority.name),\n",
    "                }, ignore_index=True)\n",
    "issues\n",
    "\n",
    "rule_value = round(len(issues.loc[~(issues['SP'].isnull())]) / len(issues), 2)\n",
    "rules.at[2, 'value'] = rule_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular project versions are grouped into bigger milestone releases. The important information is how many of those milestone items are estimated and ready to be picked up by developers. 4th rule is checking this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of key milestone items estimated and in Backlog status\n",
    "jql = 'project = VXT and type != Epic and status not in (Rejected, Completed) and \\\n",
    "type not in subTaskIssueTypes() and fixVersion in (\"' + '\", \"'.join(milestones) + '\")'\n",
    "jql\n",
    "\n",
    "issuesRaw = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['key'] = ''\n",
    "issues['version'] = ''\n",
    "issues['SP'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['summary'] = ''\n",
    "\n",
    "#add issues to dataframe\n",
    "for issue in issuesRaw:\n",
    "    #issue may have many versions - in this approach, one version per issue is recommended\n",
    "    for fixVersion in issue.fields.fixVersions:\n",
    "        if(fixVersion.name in milestones):\n",
    "            issues = issues.append(\n",
    "                {'version': fixVersion.name, \n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP': issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                }, ignore_index=True)\n",
    "            \n",
    "issues['isEstimated'] = False\n",
    "issues.loc[(issues['type'] == 'Bug'), ['isEstimated']] = True\n",
    "issues.loc[(issues['type'] != 'Bug') & ~(issues['SP'].isnull()), ['isEstimated']] = True\n",
    "issues\n",
    "\n",
    "rule_value = round(len(issues.loc[(issues['isEstimated'] == True)]) / len(issues), 2)\n",
    "rule_value\n",
    "rules.at[3, 'value'] = rule_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring calculation for each rule is quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules['score'] = rules.weight * rules.value * 10\n",
    "rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/rules_score.png\" />\n",
    "\n",
    "The scoring alone is not as important as the trend of its values in time. Using %store command of Jupyter Notebook you can conveniently store variables locally to create chart with scoring values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(sum(rules['score']), 2)\n",
    "\n",
    "#refresh stored data\n",
    "%store -r\n",
    "\n",
    "#if data frame for scores is not loaded create it\n",
    "if not 'scores' in globals():\n",
    "    scores = pd.DataFrame()\n",
    "    scores['date'] = ''\n",
    "    scores['score'] = 0\n",
    "\n",
    "#append latest score\n",
    "scores = scores.append(\n",
    "            {\n",
    "             'date': pd.to_datetime('now'),\n",
    "             'score': score,\n",
    "            }, ignore_index=True)\n",
    "\n",
    "#store scores for later use\n",
    "%store scores\n",
    "\n",
    "print(\"Backlog score {} / 10\".format(score))\n",
    "\n",
    "_ = plt.plot(scores['date'], scores['score'], \"-r.\")\n",
    "\n",
    "_ = plt.xticks(rotation='vertical')\n",
    "_ = plt.ylabel('Backlog score')\n",
    "_ = plt.xlabel('Time')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see there is a lot space for improvement on chart below. I'd recommend to send it to your team and especially PO every week.\n",
    "\n",
    "If you're interested in other notebooks that could help you working with agile teams take a look at this Github repository: https://github.com/robert-krasinski/JiraAndPythonForManagers\n",
    "\n",
    "<img src=\"./images/scoring_chart_example.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
