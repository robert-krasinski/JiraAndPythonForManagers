{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates burndown chart for specified fixVersions\n",
    "\n",
    "Specify the fixVersions that you'd like to estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixVersions = ['1.12', '1.13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data using JIRA API (https://jira.readthedocs.io/en/master/)\n",
    "\n",
    "Password is provided using ~/.rcnet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jira import JIRA\n",
    "\n",
    "\n",
    "#store credentials in ~/.rcnet file\n",
    "jira = JIRA('https://kainos-evolve.atlassian.net')\n",
    "jql = 'project=VXT and fixversion in (' + \", \".join(fixVersions) +')'\n",
    "jql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above JQL will be used to download the data from Jira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "issuesInVersions = jira.search_issues(jql)\n",
    "\n",
    "issues = pd.DataFrame()\n",
    "issues['version'] = ''\n",
    "issues['key'] = ''\n",
    "issues['type'] = ''\n",
    "issues['status'] = ''\n",
    "issues['SP'] = 0\n",
    "issues['summary'] = ''\n",
    "\n",
    "#add issues to dataframe\n",
    "for issue in issuesInVersions:\n",
    "    #issue may have many versions - in this approach, one version per issue is recommended\n",
    "    for fixVersion in issue.fields.fixVersions:\n",
    "        if(fixVersion.name in fixVersions):\n",
    "            \n",
    "            if issue.fields.aggregatetimeestimate is not None:\n",
    "                remainingTime = issue.fields.aggregatetimeestimate / 60 / 60 / 8 #in days\n",
    "            else:\n",
    "                remainingTime = np.nan\n",
    "            \n",
    "            issues = issues.append(\n",
    "                {'version': fixVersion.name, \n",
    "                 'key': issue.key,\n",
    "                 'type': issue.fields.issuetype.name,\n",
    "                 'status': issue.fields.status.name,\n",
    "                 'SP': issue.fields.customfield_10005,\n",
    "                 'summary': issue.fields.summary,\n",
    "                 'team' : str(issue.fields.customfield_14200),\n",
    "                 'remainingTime' : remainingTime\n",
    "                }, ignore_index=True)\n",
    "            \n",
    "issues.sort_values(\"version\", inplace=True)\n",
    "issues = issues.loc[~(issues['status'].isin(['Completed', 'Rejected']))]\n",
    "issues = issues.loc[(issues['team'].isin(['Gdansk Team 1']))]\n",
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "###### All stories should have SP value\n",
    "\n",
    "Please review items below and add SP to issues where necessary. Missing estimations my skew the results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues.loc[(issues['type'] == 'Story') & (issues['SP'].isnull())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use remaining time if possible\n",
    "For better accuracy use remainingTime field instead of SP when possible. \n",
    "Setting 0 in SP field where remainingTime is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues.loc[~(issues['remainingTime'].isnull()), ['SP']] = 0\n",
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN values by 0 for grouping\n",
    "issues = issues.fillna(0)\n",
    "#issues = issues.groupby(['version'], as_index=False)['SP'].sum()\n",
    "issues = issues.groupby(['version']).agg({'SP':'sum','remainingTime':'sum'})\n",
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually calculate and set minimum, average and maximum velocity for the team "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minVelocity = 6\n",
    "avgVelocity = 13\n",
    "maxVelocity = 20.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate days using velocity above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "versions = pd.DataFrame()\n",
    "#add some data to play with first\n",
    "#versions['version'] = ['1.12', '1.13', '1.14']\n",
    "#versions['SP'] = [33, 40, 38]\n",
    "\n",
    "#or get data directly from Jira\n",
    "versions = issues\n",
    "\n",
    "import math\n",
    "# BDay is business day, not birthday...\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "#calculate days for each version using velocity and adjust with remaining time\n",
    "versions['minVeloDays'] = np.ceil(versions.SP * 10 / minVelocity).astype(int) + versions.remainingTime\n",
    "versions['avgVeloDays'] = np.ceil(versions.SP * 10 / avgVelocity).astype(int) + versions.remainingTime\n",
    "versions['maxVeloDays'] = np.ceil(versions.SP * 10 / maxVelocity).astype(int) + versions.remainingTime\n",
    "\n",
    "#round up days\n",
    "minVeloDays = math.ceil(sum(versions.minVeloDays))\n",
    "avgVeloDays = math.ceil(sum(versions.avgVeloDays))\n",
    "maxVeloDays = math.ceil(sum(versions.maxVeloDays))\n",
    "\n",
    "\n",
    "#calculate rolling sum of days up to the version\n",
    "versions['minSum'] = versions.minVeloDays.expanding(1).sum().astype(int)\n",
    "versions['avgSum'] = versions.avgVeloDays.expanding(1).sum().astype(int)\n",
    "versions['maxSum'] = versions.maxVeloDays.expanding(1).sum().astype(int)\n",
    "\n",
    "#replace NaN with 0\n",
    "versions = versions.fillna(0)\n",
    "\n",
    "#add business days to today to calculate finish date\n",
    "versions['finishDateMinVelo'] = 0\n",
    "versions['finishDateAvgVelo'] = 0\n",
    "versions['finishDateMaxVelo'] = 0\n",
    "\n",
    "\n",
    "versions.finishDateMinVelo = versions.minSum.apply(lambda x: pd.to_datetime('today') + BDay(x))\n",
    "versions.finishDateAvgVelo = versions.avgSum.apply(lambda x: pd.to_datetime('today') + BDay(x))\n",
    "versions.finishDateMaxVelo = versions.maxSum.apply(lambda x: pd.to_datetime('today') + BDay(x))\n",
    "\n",
    "versions['minVeloDaysToFinish'] = 0\n",
    "versions['avgVeloDaysToFinish'] = 0\n",
    "versions['maxVeloDaysToFinish'] = 0\n",
    "versions.minVeloDaysToFinish = minVeloDays - versions.minSum\n",
    "versions.avgVeloDaysToFinish = avgVeloDays - versions.avgSum\n",
    "versions.maxVeloDaysToFinish = maxVeloDays - versions.maxSum\n",
    "\n",
    "versions = versions.reset_index()\n",
    "\n",
    "#add first row with today to create burndown chart\n",
    "versions = versions.append(\n",
    "        {\n",
    "          'version': 'today', \n",
    "         'finishDateMinVelo': pd.to_datetime('today'),\n",
    "         'finishDateMaxVelo': pd.to_datetime('today'),\n",
    "         'finishDateAvgVelo': pd.to_datetime('today'),\n",
    "         'minVeloDaysToFinish': minVeloDays,\n",
    "         'avgVeloDaysToFinish': avgVeloDays,\n",
    "         'maxVeloDaysToFinish': maxVeloDays\n",
    "        }, ignore_index=True)\n",
    "\n",
    "versions.sort_values(\"finishDateMinVelo\", inplace=True)\n",
    "\n",
    "versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (25, 20)\n",
    "\n",
    "_ = plt.plot(versions['finishDateMinVelo'], versions['minVeloDaysToFinish'], \"-r.\")\n",
    "_ = plt.plot(versions['finishDateAvgVelo'], versions['avgVeloDaysToFinish'], \"-g.\")\n",
    "_ = plt.plot(versions['finishDateMaxVelo'], versions['maxVeloDaysToFinish'], \"-b.\")\n",
    "\n",
    "_ = plt.xticks(rotation='vertical')\n",
    "\n",
    "for label, x, y in zip(versions['version'], versions['finishDateMinVelo'], versions['minVeloDaysToFinish']):\n",
    "    _ = plt.annotate(\n",
    "        label + \" \" + x.strftime('%Y-%m-%d'),\n",
    "        xy=(x, y), xytext=(-20, 20),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    \n",
    "for label, x, y in zip(versions['version'], versions['finishDateAvgVelo'], versions['avgVeloDaysToFinish']):\n",
    "    _ = plt.annotate(\n",
    "        label + \" \" + x.strftime('%Y-%m-%d'),\n",
    "        xy=(x, y), xytext=(-20, 20),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "\n",
    "for label, x, y in zip(versions['version'], versions['finishDateMaxVelo'], versions['maxVeloDaysToFinish']):\n",
    "    _ = plt.annotate(\n",
    "        label + \" \" + x.strftime('%Y-%m-%d'),\n",
    "        xy=(x, y), xytext=(-20, 20),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
